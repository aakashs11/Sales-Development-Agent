{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1cca935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandasai import SmartDataframe\n",
    "from pandasai.llm import OpenAI\n",
    "#add todays date\n",
    "\n",
    "import pandas as pd\n",
    "llm = OpenAI(model=\"gpt-4o-mini\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69ea412a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IOException",
     "evalue": "IO Error: File is already open in \nC:\\Users\\AakashAI\\AppData\\Local\\Programs\\Python\\Python312\\python.exe (PID 15484)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIOException\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m df_master = pd.read_csv(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mAakashAI\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDesktop\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mRepositories\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSales Agent\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mmerged_leads.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m columns=\u001b[38;5;28mlist\u001b[39m(df_master.columns)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m sdf = \u001b[43mSmartDataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_master\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mllm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcustom_prompts\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpandas_code\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m You are analyzing a sales leads dataset. Columns include \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcolumns\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m Be careful with column names and types.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbose\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AakashAI\\Desktop\\Repositories\\Sales Agent\\.venv\\Lib\\site-packages\\pandasai\\smart_dataframe\\__init__.py:63\u001b[39m, in \u001b[36mSmartDataframe.__init__\u001b[39m\u001b[34m(self, df, name, description, custom_head, config)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[33;03m    df: A supported dataframe type, or a pandasai Connector\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     59\u001b[39m \u001b[33;03m    config (Config, optional): Config to be used. Defaults to None.\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28mself\u001b[39m._original_import = df\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[38;5;28mself\u001b[39m._agent = \u001b[43mAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28mself\u001b[39m.dataframe = \u001b[38;5;28mself\u001b[39m._agent.context.dfs[\u001b[32m0\u001b[39m]\n\u001b[32m     67\u001b[39m \u001b[38;5;28mself\u001b[39m._table_description = description\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AakashAI\\Desktop\\Repositories\\Sales Agent\\.venv\\Lib\\site-packages\\pandasai\\agent\\agent.py:28\u001b[39m, in \u001b[36mAgent.__init__\u001b[39m\u001b[34m(self, dfs, config, memory_size, pipeline, vectorstore, description, judge, security)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     17\u001b[39m     dfs: Union[\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m     security: BaseSecurity = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     27\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecurity\u001b[49m\u001b[43m=\u001b[49m\u001b[43msecurity\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28mself\u001b[39m.pipeline = (\n\u001b[32m     33\u001b[39m         pipeline(\n\u001b[32m     34\u001b[39m             \u001b[38;5;28mself\u001b[39m.context,\n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m         )\n\u001b[32m     52\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AakashAI\\Desktop\\Repositories\\Sales Agent\\.venv\\Lib\\site-packages\\pandasai\\agent\\base.py:76\u001b[39m, in \u001b[36mBaseAgent.__init__\u001b[39m\u001b[34m(self, dfs, config, memory_size, vectorstore, description, security)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Instantiate the context\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;28mself\u001b[39m.config = \u001b[38;5;28mself\u001b[39m.get_config(config)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28mself\u001b[39m.context = \u001b[43mPipelineContext\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMemory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemory_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Instantiate the logger\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;28mself\u001b[39m.logger = Logger(\n\u001b[32m     85\u001b[39m     save_logs=\u001b[38;5;28mself\u001b[39m.config.save_logs, verbose=\u001b[38;5;28mself\u001b[39m.config.verbose\n\u001b[32m     86\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AakashAI\\Desktop\\Repositories\\Sales Agent\\.venv\\Lib\\site-packages\\pandasai\\pipelines\\pipeline_context.py:35\u001b[39m, in \u001b[36mPipelineContext.__init__\u001b[39m\u001b[34m(self, dfs, config, memory, skills_manager, cache, vectorstore, initial_values)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mself\u001b[39m.skills_manager = skills_manager \u001b[38;5;129;01mor\u001b[39;00m SkillsManager()\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.enable_cache:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[38;5;28mself\u001b[39m.cache = cache \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     37\u001b[39m     \u001b[38;5;28mself\u001b[39m.cache = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AakashAI\\Desktop\\Repositories\\Sales Agent\\.venv\\Lib\\site-packages\\pandasai\\helpers\\cache.py:32\u001b[39m, in \u001b[36mCache.__init__\u001b[39m\u001b[34m(self, filename, abs_path)\u001b[39m\n\u001b[32m     29\u001b[39m os.makedirs(cache_dir, mode=DEFAULT_FILE_PERMISSIONS, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     31\u001b[39m \u001b[38;5;28mself\u001b[39m.filepath = os.path.join(cache_dir, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.db\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28mself\u001b[39m.connection = \u001b[43mduckdb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mself\u001b[39m.connection.execute(\n\u001b[32m     34\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCREATE TABLE IF NOT EXISTS cache (key STRING, value STRING)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     35\u001b[39m )\n",
      "\u001b[31mIOException\u001b[39m: IO Error: File is already open in \nC:\\Users\\AakashAI\\AppData\\Local\\Programs\\Python\\Python312\\python.exe (PID 15484)"
     ]
    }
   ],
   "source": [
    "df_master = pd.read_csv(r'C:\\Users\\AakashAI\\Desktop\\Repositories\\Sales Agent\\merged_leads.csv')\n",
    "columns=list(df_master.columns)\n",
    "sdf = SmartDataframe(df_master, config={\n",
    "    \"llm\": llm,\n",
    "    \"custom_prompts\": {\n",
    "        \"pandas_code\": f\" You are analyzing a sales leads dataset. Columns include {columns} Be careful with column names and types.\",\n",
    "    },\n",
    "    \"verbose\": True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e9274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-13 14:24:43 [INFO] Question: Show leads from landing page and with employment status unemployed\n",
      "2025-04-13 14:24:44 [INFO] Running PandasAI with openai LLM...\n",
      "2025-04-13 14:24:44 [INFO] Prompt ID: 10cdec60-19fd-4fad-bc62-209403633d90\n",
      "2025-04-13 14:24:44 [INFO] Executing Pipeline: GenerateChatPipeline\n",
      "2025-04-13 14:24:44 [INFO] Executing Step 0: ValidatePipelineInput\n",
      "2025-04-13 14:24:44 [INFO] Executing Step 1: CacheLookup\n",
      "2025-04-13 14:24:44 [INFO] Using cached response\n",
      "2025-04-13 14:24:44 [INFO] Executing Step 2: PromptGeneration\n",
      "2025-04-13 14:24:44 [INFO] Executing Step 2: Skipping...\n",
      "2025-04-13 14:24:44 [INFO] Executing Step 3: CodeGenerator\n",
      "2025-04-13 14:24:44 [INFO] Executing Step 3: Skipping...\n",
      "2025-04-13 14:24:44 [INFO] Executing Step 4: CachePopulation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_4380\\1521114249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-13 14:24:44 [INFO] Executing Step 4: Skipping...\n",
      "2025-04-13 14:24:44 [INFO] Executing Step 5: CodeCleaning\n",
      "2025-04-13 14:24:44 [INFO] \n",
      "Code running:\n",
      "```\n",
      "filtered_leads = dfs[0][(dfs[0]['Landing Page'] == 'Landing Page Submission') & (dfs[0]['What is your current occupation_x'] == 'Unemployed')]\n",
      "result = {'type': 'dataframe', 'value': filtered_leads}\n",
      "        ```\n",
      "2025-04-13 14:24:44 [INFO] Executing Step 6: CodeExecution\n",
      "2025-04-13 14:24:44 [INFO] Executing Step 7: ResultValidation\n",
      "2025-04-13 14:24:44 [INFO] Answer: {'type': 'dataframe', 'value': Empty DataFrame\n",
      "Columns: [Prospect ID, Lead Number_x, Lead Origin_x, Lead Source_x, Do Not Email_x, Do Not Call_x, Converted, TotalVisits_x, Total Time Spent on Website, Page Views Per Visit_x, Last Activity_x, Country_x, Specialization_x, How did you hear about X Education, What is your current occupation_x, What matters most to you in choosing a course, Search_x, Magazine_x, Newspaper Article_x, X Education Forums, Newspaper_x, Digital Advertisement_x, Through Recommendations_x, Receive More Updates About Our Courses_x, Tags_x, Lead Quality_x, Update me on Supply Chain Content_x, Get updates on DM Content, Lead Profile_x, City, Asymmetrique Activity Index_x, Asymmetrique Profile Index_x, Asymmetrique Activity Score_x, Asymmetrique Profile Score_x, I agree to pay the amount through cheque_x, A free copy of Mastering The Interview, Last Notable Activity_x, Lead Number_y, Company, Lead Origin_y, Mobile Number, Website, Time Zone, Job Title, Lead Source_y, Source Medium, Notes, Source Campaign, Source Content, Do Not Email_y, Do Not Call_y, Lead Stage, Lead Grade, Lead Score, Order Value, Engagement Score, TotalVisits_y, Page Views Per Visit_y, Average Time Per Visit, Last Activity_y, Last Activity Date, Related Landing Page Id, First Landing Page Submission Id, First Landing Page Submission Date, Created On, Modified On, Lead Conversion Date, Address 1, Address 2, Cityold, State, Country_y, Zip, Facebook URL, Twitter URL, LinkedIn URL, Industry, Work Area, Course Interested, Keyword, Date, Specialization_y, Entrance Test, How did you hear about SomeSchool, What is your current occupation_y, If you are a working professional, If you are a working professional please mention , What matters most to you in choosing an ADP, Age, Next Follow Up, Search_y, Magazine_y, Newspaper Article_y, Welearn Forums, Newspaper_y, Digital Advertisement_y, Through Recommendations_y, Any other Please specify, Last Degree, Receive More Updates About Our Courses_y, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 159 columns]}\n",
      "2025-04-13 14:24:44 [INFO] Executing Step 8: ResultParsing\n"
     ]
    }
   ],
   "source": [
    "response = sdf.chat(\"Show leads from landing page and with employment status unemployed\")\n",
    "df = (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257c412a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prospect ID</th>\n",
       "      <th>Lead Number_x</th>\n",
       "      <th>Lead Origin_x</th>\n",
       "      <th>Lead Source_x</th>\n",
       "      <th>Do Not Email_x</th>\n",
       "      <th>Do Not Call_x</th>\n",
       "      <th>Converted</th>\n",
       "      <th>TotalVisits_x</th>\n",
       "      <th>Total Time Spent on Website</th>\n",
       "      <th>Page Views Per Visit_x</th>\n",
       "      <th>...</th>\n",
       "      <th>Mailing Preferences</th>\n",
       "      <th>Twitter Id</th>\n",
       "      <th>Facebook Id</th>\n",
       "      <th>LinkedIn Id</th>\n",
       "      <th>Skype Id</th>\n",
       "      <th>Gtalk Id</th>\n",
       "      <th>Google Plus Id</th>\n",
       "      <th>Quality Score 01</th>\n",
       "      <th>Groups</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Prospect ID, Lead Number_x, Lead Origin_x, Lead Source_x, Do Not Email_x, Do Not Call_x, Converted, TotalVisits_x, Total Time Spent on Website, Page Views Per Visit_x, Last Activity_x, Country_x, Specialization_x, How did you hear about X Education, What is your current occupation_x, What matters most to you in choosing a course, Search_x, Magazine_x, Newspaper Article_x, X Education Forums, Newspaper_x, Digital Advertisement_x, Through Recommendations_x, Receive More Updates About Our Courses_x, Tags_x, Lead Quality_x, Update me on Supply Chain Content_x, Get updates on DM Content, Lead Profile_x, City, Asymmetrique Activity Index_x, Asymmetrique Profile Index_x, Asymmetrique Activity Score_x, Asymmetrique Profile Score_x, I agree to pay the amount through cheque_x, A free copy of Mastering The Interview, Last Notable Activity_x, Lead Number_y, Company, Lead Origin_y, Mobile Number, Website, Time Zone, Job Title, Lead Source_y, Source Medium, Notes, Source Campaign, Source Content, Do Not Email_y, Do Not Call_y, Lead Stage, Lead Grade, Lead Score, Order Value, Engagement Score, TotalVisits_y, Page Views Per Visit_y, Average Time Per Visit, Last Activity_y, Last Activity Date, Related Landing Page Id, First Landing Page Submission Id, First Landing Page Submission Date, Created On, Modified On, Lead Conversion Date, Address 1, Address 2, Cityold, State, Country_y, Zip, Facebook URL, Twitter URL, LinkedIn URL, Industry, Work Area, Course Interested, Keyword, Date, Specialization_y, Entrance Test, How did you hear about SomeSchool, What is your current occupation_y, If you are a working professional, If you are a working professional please mention , What matters most to you in choosing an ADP, Age, Next Follow Up, Search_y, Magazine_y, Newspaper Article_y, Welearn Forums, Newspaper_y, Digital Advertisement_y, Through Recommendations_y, Any other Please specify, Last Degree, Receive More Updates About Our Courses_y, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 159 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afae11dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function\n",
    "def parse_pandasai_output(output):\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    if isinstance(output, pd.DataFrame):\n",
    "        print(\"→ Output is a DataFrame\")\n",
    "        display(output)  # For Jupyter or IPython\n",
    "        return {\"type\": \"dataframe\", \"data\": output}\n",
    "\n",
    "    elif isinstance(output, (int, float, str, bool)):\n",
    "        print(f\"→ Output is a {type(output).__name__}: {output}\")\n",
    "        return {\"type\": \"scalar\", \"data\": output}\n",
    "\n",
    "    elif isinstance(output, dict):\n",
    "        print(\"→ Output is a dictionary\")\n",
    "        return {\"type\": \"dict\", \"data\": output}\n",
    "\n",
    "    elif isinstance(output, (list, tuple)):\n",
    "        print(\"→ Output is a list/tuple\")\n",
    "        return {\"type\": \"list\", \"data\": output}\n",
    "\n",
    "    elif isinstance(output, plt.Figure):\n",
    "        print(\"→ Output is a Matplotlib Figure (chart)\")\n",
    "        plt.show()\n",
    "        return {\"type\": \"figure\", \"data\": output}\n",
    "\n",
    "    else:\n",
    "        print(f\"→ Output is of unexpected type: {type(output)}\")\n",
    "        return {\"type\": \"unknown\", \"data\": output}\n",
    "def nl_to_query_fallback(nl_query):\n",
    "    df_master = pd.read_csv(r'C:\\Users\\AakashAI\\Desktop\\Repositories\\Sales Agent\\merged_leads.csv')\n",
    "    sdf = SmartDataframe(df_master, config={\n",
    "        \"llm\": llm,\n",
    "        \"custom_prompts\": {\n",
    "            \"pandas_code\": f\" You are analyzing a sales leads dataset. Columns include {columns} Be careful with column names and types.\",\n",
    "        },\n",
    "        \"verbose\": False\n",
    "    })\n",
    "    try:\n",
    "        response = sdf.chat(nl_query)\n",
    "        return parse_pandasai_output(response)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0060eb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-12 21:58:47 [INFO] Question: How many leads from google\n",
      "2025-04-12 21:58:47 [INFO] Running PandasAI with openai LLM...\n",
      "2025-04-12 21:58:47 [INFO] Prompt ID: 7c429851-0fd3-45ae-bb3e-fb96f3aa47d3\n",
      "2025-04-12 21:58:47 [INFO] Executing Pipeline: GenerateChatPipeline\n",
      "2025-04-12 21:58:47 [INFO] Executing Step 0: ValidatePipelineInput\n",
      "2025-04-12 21:58:47 [INFO] Executing Step 1: CacheLookup\n",
      "2025-04-12 21:58:48 [INFO] Using cached response\n",
      "2025-04-12 21:58:48 [INFO] Executing Step 2: PromptGeneration\n",
      "2025-04-12 21:58:48 [INFO] Executing Step 2: Skipping...\n",
      "2025-04-12 21:58:48 [INFO] Executing Step 3: CodeGenerator\n",
      "2025-04-12 21:58:48 [INFO] Executing Step 3: Skipping...\n",
      "2025-04-12 21:58:48 [INFO] Executing Step 4: CachePopulation\n",
      "2025-04-12 21:58:48 [INFO] Executing Step 4: Skipping...\n",
      "2025-04-12 21:58:48 [INFO] Executing Step 5: CodeCleaning\n",
      "2025-04-12 21:58:48 [INFO] \n",
      "Code running:\n",
      "```\n",
      "google_leads_count = sum(dfs[0]['Lead Source_x'] == 'Google') + sum(dfs[0]['Lead Source_y'] == 'Google')\n",
      "result = {'type': 'number', 'value': google_leads_count}\n",
      "print(result)\n",
      "        ```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n",
      "C:\\Users\\AakashAI\\AppData\\Local\\Temp\\ipykernel_20692\\1392018402.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  response = sdf.chat(nl_query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-12 21:58:48 [INFO] Executing Step 6: CodeExecution\n",
      "{'type': 'number', 'value': 24}\n",
      "2025-04-12 21:58:48 [INFO] Executing Step 7: ResultValidation\n",
      "2025-04-12 21:58:48 [INFO] Answer: {'type': 'number', 'value': 24}\n",
      "2025-04-12 21:58:48 [INFO] Executing Step 8: ResultParsing\n",
      "→ Output is a int: 24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'scalar', 'data': 24}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nl_to_query_fallback(\"How many leads from google\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d64e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
